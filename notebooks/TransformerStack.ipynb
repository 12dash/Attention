{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23ea401a-7d84-465d-9eab-ef1639810493",
   "metadata": {},
   "source": [
    "# Transformer Stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23c59d3f-e98d-4f0f-b92c-a69c8584d86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a772d1b-3b24-472c-82d0-6d39e675adad",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScaledDotProductAttention(nn.Module):\n",
    "    def __init__(self, d):\n",
    "        super().__init__()\n",
    "        self.normalization_factor = d**0.5\n",
    "\n",
    "    def forward(self, q, k, v, mask = None):\n",
    "        unnormalized = F.softmax(torch.matmul(q, torch.transpose(k, -2, -1)), dim = -1)\n",
    "        normalized = unnormalized / self.normalization_factor \n",
    "        if mask is not None:\n",
    "            normalized = torch.mul(mask, normalized)\n",
    "        attention_value = torch.matmul(normalized, v) \n",
    "        return attention_value, normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a7478d0-5f10-4c82-8405-f43ebda2183a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self, input_dim, embedding_dim):\n",
    "        super().__init__()\n",
    "\n",
    "        self.query_weights = nn.Linear(input_dim, embedding_dim)\n",
    "        self.key_weights = nn.Linear(input_dim, embedding_dim)\n",
    "        self.value_weights = nn.Linear(input_dim, embedding_dim)\n",
    "\n",
    "        self.scaled_attention = ScaledDotProductAttention(embedding_dim)\n",
    "\n",
    "    def forward(self, q, k, v):\n",
    "        q = self.query_weights(q)\n",
    "        k = self.key_weights(k) \n",
    "        v = self.value_weights(v)\n",
    "\n",
    "        attention, attention_weights = self.scaled_attention(q, k, v)\n",
    "        return attention, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82416c5b-7673-410f-a3ba-00eb19cee824",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, input_dim, num_heads, embedding_dim, output_dim):\n",
    "        super().__init__()\n",
    "        assert (embedding_dim % num_heads == 0), f\"embedding dim {embedding_dim} must be divisible by num heads {num_heads}\"\n",
    "        \n",
    "        self.input_dim = input_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.embedding_dim = embedding_dim // num_heads\n",
    "        self.multihead_attention = [(Attention(input_dim, self.embedding_dim)) for _ in range(num_heads)]\n",
    "\n",
    "        self.output_projection = nn.Linear(embedding_dim, output_dim)\n",
    "    \n",
    "    def forward(self, q, k, v):\n",
    "        attention_list, weights_list = [], []\n",
    "        for attention_head in self.multihead_attention:\n",
    "            attention, attention_weights = attention_head(q, k, v)\n",
    "            attention_list.append(attention)\n",
    "            weights_list.append(attention_weights.unsqueeze(dim = 1))\n",
    "        \n",
    "        attention = torch.cat(attention_list, dim = -1)\n",
    "        weights_list = torch.cat(weights_list, dim = 1)\n",
    "        attention = self.output_projection(attention)\n",
    "        return attention, weights_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adcad322-d6c3-417b-a921-9b75304948a3",
   "metadata": {},
   "source": [
    "# Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "104b2175-82d5-4d2c-9c4a-8784fb216668",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, embedding_dim, output_dim, num_heads):\n",
    "        super().__init__()\n",
    "        self.multi_head_attn = MultiHeadAttention(input_dim, num_heads, \n",
    "                                                  embedding_dim, \n",
    "                                                  output_dim)\n",
    "        self.layer_norm_inter = nn.LayerNorm(output_dim)\n",
    "        self.fc = nn.Sequential(*[\n",
    "            nn.Linear(output_dim, output_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(output_dim, output_dim),\n",
    "        ])\n",
    "        self.layer_norm_final = nn.LayerNorm(output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        attn, attn_weights = self.multi_head_attn(x, x, x)\n",
    "        x = x + attn\n",
    "        x = self.layer_norm_inter(x)\n",
    "        fc_result = self.fc(x)\n",
    "        x = self.layer_norm_final(fc_result + x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "176e37f0-581e-479d-9c7d-62b4294e7014",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "seq_len = 10\n",
    "\n",
    "input_dim = 128\n",
    "embedding_dim = 128\n",
    "output_dim = 128\n",
    "num_heads = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d8cc9742-695e-46a0-9b1b-ae3d18b8d54d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder output dim :  torch.Size([8, 10, 128])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(size=(batch_size, seq_len, input_dim))\n",
    "enc = Encoder(input_dim, embedding_dim, output_dim, num_heads)\n",
    "print(\"Encoder output dim : \", enc(x).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78883294-3b36-471b-9c3f-0d49ccb6c631",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# Decoder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d8a47aa-0f9b-4edc-bed7-c79f1b4775e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, input_dim, embedding_dim, output_dim, num_heads):\n",
    "        super().__init__()\n",
    "        self.multi_head_attn_1 = MultiHeadAttention(input_dim, num_heads, \n",
    "                                                  embedding_dim, \n",
    "                                                  output_dim)\n",
    "        self.layer_norm_1 = nn.LayerNorm(output_dim)\n",
    "        self.multi_head_attn_2 = MultiHeadAttention(output_dim, num_heads, \n",
    "                                                    output_dim, \n",
    "                                                    output_dim)\n",
    "        self.layer_norm_2 = nn.LayerNorm(output_dim)\n",
    "        self.fc = nn.Sequential(*[\n",
    "            nn.Linear(output_dim, output_dim), \n",
    "            nn.ReLU(), \n",
    "            nn.Linear(output_dim, output_dim)\n",
    "        ])\n",
    "        self.layer_norm_final = nn.LayerNorm(output_dim)\n",
    "\n",
    "    def forward(self, x, encoder):\n",
    "        attn, attn_weights = self.multi_head_attn_1(x, x, x)\n",
    "        x = self.layer_norm_1(x + attn)\n",
    "        attn, attn_weights = self.multi_head_attn_2(x, encoder, encoder)\n",
    "        x = self.layer_norm_2(x + attn)\n",
    "        x = self.fc(x)\n",
    "        x = self.layer_norm_final(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f6ed36af-daa7-4f61-96eb-cfd9f60ef5dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoder output dim :  torch.Size([8, 10, 128])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(size=(batch_size, seq_len, input_dim))\n",
    "enc = Encoder(input_dim, embedding_dim, output_dim, num_heads)\n",
    "encoder = enc.forward(x)\n",
    "\n",
    "dec = Decoder(input_dim, embedding_dim, output_dim, num_heads)\n",
    "print(\"Decoder output dim : \", dec(x, encoder).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cfac0ff-1657-411a-a291-219a4239866f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
